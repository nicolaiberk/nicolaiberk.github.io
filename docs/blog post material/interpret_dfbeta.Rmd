---
title: "Outliers"
author: "Nicolai Berk"
date: "3 12 2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, message = F}
# load packages
library(AER)
library(stargazer)
library(ggplot2)
library(GGally) # scatterplots via GGpairs
library(lmtest) # BP test, coeftest
library(car) # vif test for MC, 

# Load and prepare data
?CPS1985
data("CPS1985")
rownames(CPS1985) <- index(CPS1985)
```

This brief guide is supposed to explain the interpretation of dfBetas, both standardised and non-standardised. I load data and packages above. Note that I assigned the index of our data as the rownames. Taking care of this at the beginning of your script helps improve the interpretability of your plots to identify outliers (sometimes the rownames might be random numbers, this way you make sure that the rownames run from 1 to the number of observations).  After preparing the data in this way (and dropping possible outliers), we fit our model of interest:

```{r model}
m3 <- lm(wage ~ education + experience*gender, data = CPS1985) # Model with interaction.
summary(m3)
```
You know these estimates from the lab, so I am going to check for outliers right away, using avPlots():

```{r avPlots}
avPlots(m3)
```

Remember that these plots show the relationship of each indpendent with your dependent variable, controlling for all other variables. This way, we can see what the correlation of the variables in the model looks like. Simple scatterplots do not take into account that some of the variation is explained by other variables.

We can see that observation #171 is somewhat of an outlier, always showing strong discrepancy (deviation from the predicted values). It also shows some leverage, as it deviates somewhat from the average value for gender, controlling for all other variables. It is quite possible that it would affect our estimates hence. We can check if that is the case using dfBetas:

```{r dfbetas}
dfbetasPlots(m3, id.n=5, labels=rownames(CPS1985))
```

Remember that dfbetasPlots() shows how strongly a single observation affects your model estimates. It does so by estimating the model, dropping each observation once. Then, it calculates the standard deviation and indicates by how many standard deviations the effect would change. While the estimates for education and experience seem rather unaffected by single observations, observation #171 deviates quite a bit from the overall trend. Note that this is not a lot in terms of standard deviations (around 0.7 sd for gender, -0.6 for the interaction coefficient), so we could conclude that the estimate is not strongly effected and that we do not have outliers. But since we are cautious sticklers, we will estimate *how much* our model is affected. We can check this (to be sure) by using dfbetaPlots(), which shows the non-standardised deviation in the effect (we're focusing on the gender variable here):

```{r dfbeta}
dfbetaPlots(m3, ~gender, id.n=5, labels=rownames(CPS1985))
```

The scale has changed, as it now shows the absolute effect of the outlier on gender. Observation #171 biases the estimate upwards by something between 0.4 and 0.5. Given that the estimate from our model above was -0.67, with a standard error of 0.68, this is a substantial effect for a single observation, despite the fact that it is $<1$ standard deviation in the dfbetasPlot(). So - to be sure - let's estimate a model without the outlier:


```{r m3_robust, warning=F}
m3_robust <- lm(wage ~ education + experience*gender, data = CPS1985[-171,]) # Model without outlier
stargazer(m3, m3_robust, type = "text", column.labels = c("Full data", "No Outliers"))
```
Note that we can only drop the outlier this simple (```CPS1985[-171,]```) since we assigned the index as rownames with ```rownames(CPS1985) <- index(CPS1985)``` earlier. As you can see, the estimate for gender changed from $-0.675$ to $-1.150$ - a change of $-0.475$! This is the dfbeta (non-standardised) for observation #171 and also what is displayed in ```dfbetaPlots()``` above - #171 biased the estimate upward by $0.475$ (see below). Also note that - in line with our expectation based on the ```dfbetasPlots()``` earlier - the estimate for the interaction increased (decreased in size).

```{r dfbeta_out}
as.data.frame(dfbeta(m3))[171, "genderfemale"]
```

Note that this last bit is only included to explain the concept of dfbeta to you - you are not expected to show this in your FDA! The 'secure' way would be to include the model with outliers in the appendix and to report the slight changes with an overall similar interpretation of the model.
